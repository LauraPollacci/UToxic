{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3154f444",
   "metadata": {},
   "source": [
    "# Textual Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c590cf5",
   "metadata": {},
   "source": [
    "This analysis focuses on the toxic comments, which have a value of the feature \"toxicity\" >= 0.7\n",
    "<br>\n",
    "<br>\n",
    "Wordcloud extracts the most frequent words from these comments, TF-IDF identifies the most relevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacf0a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "nltk.download(\"popular\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a24446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv file\n",
    "df = pd.read_csv(\"../.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66425e34",
   "metadata": {},
   "source": [
    "Definition of toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284cf7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def toxic(x):\n",
    "    if x >= 0.7:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "#binary feature: 1 if comment is toxic, 0 otherwise\n",
    "df[\"toxic\"] = df[\"toxicity\"].apply(toxic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3977297",
   "metadata": {},
   "source": [
    "<h2>WordCloud</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tox = df[df[\"toxic\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f73f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_wc = []\n",
    "#function that generates wordclouds, considering top 150.000 toxic comments\n",
    "def generate_word_cloud(col_name):\n",
    "    documents = df_tox.sort_values(by=col_name, ascending = False)\n",
    "    documents_text = documents[\"text\"][:150000].tolist()\n",
    "    texts = \" \".join(documents_text).lower()\n",
    "    wc = WordCloud(\n",
    "        max_font_size = 100,\n",
    "        max_words = 200,\n",
    "        background_color = 'white',\n",
    "        stopwords = stop_words,\n",
    "        font_path = \"16020_FUTURAM.ttf\"\n",
    "    ).generate(texts)\n",
    "    for k,v in wc.words_.items():\n",
    "        #biggest words\n",
    "        if v >= 0.5:\n",
    "            words_wc.append(k)\n",
    "    fig, ax = plt.subplots(1, 1, figsize = (10, 10))\n",
    "    ax.set_title(f\"{col_name.replace('_', ' ').title()}\", fontsize = 20)\n",
    "    ax.imshow(wc, interpolation = 'bilinear')\n",
    "    ax.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b9ed2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7415ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"severe_toxicity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f89ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"obscene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9c7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"threat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c227d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"insult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ddd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(\"identity_attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cd929f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set of toxic words\n",
    "words_wc_set = set(words_wc)\n",
    "len(words_wc_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43f1bb9",
   "metadata": {},
   "source": [
    "<h2>TF-IDF</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f0c318",
   "metadata": {},
   "source": [
    "toxicity è quella coi valori più alti di correlazione, ordino il dataset per quella e prendo i top tossici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d71a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tfidf = []\n",
    "#Identification of relevant words using TF-IDF\n",
    "def tf_idf(colname):\n",
    "    documents = df_tox.sort_values(by=colname, ascending = False)\n",
    "    documents_text = documents[\"text\"][:150000]\n",
    "    vectorizer = TfidfVectorizer(stop_words = \"english\")\n",
    "    tfidf_matrix = vectorizer.fit_transform(documents_text)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    tfidf_array = tfidf_matrix.toarray()\n",
    "    tfidf_df = pd.DataFrame(tfidf_array, columns=feature_names)\n",
    "    mean_tfidf = tfidf_df.mean(axis=0)\n",
    "    sorted_mean_tfidf = mean_tfidf.sort_values(ascending=False)\n",
    "    top_terms = sorted_mean_tfidf.head(10)\n",
    "    for k, v in top_terms.items():\n",
    "        words_tfidf.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bafde5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxicities = [\"toxicity\",\"obscene\",\"insult\",\"severe_toxicity\",\"identity_attack\",\"threat\"]\n",
    "for i in toxicities:\n",
    "    tf_idf(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_tfidf_set = set(words_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cfe4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_union = words_tfidf_set | words_wc_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6655b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6521d019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization of words\n",
    "def lemmatize(w_set):\n",
    "    words_lemma = []\n",
    "    for i in w_set:\n",
    "        doc = nlp(i)\n",
    "        for token in doc:\n",
    "            words_lemma.append(token.lemma_)\n",
    "    return set(words_lemma)\n",
    "    \n",
    "wc_lemmas = lemmatize(words_union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7adb557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#every word is inserted as binary feature (1 if the word is present in comment, 0 otherwise)\n",
    "for word in wc_lemmas:\n",
    "    df[word] = df['text'].str.contains(word).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aebe17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#esport dataset\n",
    "#df.to_csv(\"../file_csv/PIANO_comments.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
